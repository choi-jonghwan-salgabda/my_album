# save_face_json_with_polygon.py

import os
import sys
import yaml
import json
import hashlib
import logging
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Union, Any # <--- Add Union and Any here
from PIL import Image
import numpy as np
import cv2
import mediapipe as mp

# === ì„¤ì • ===
mp_face_mesh = mp.solutions.face_mesh

# === ë¡œê¹… ì„¤ì • ===
log_dir = Path("logs")
log_dir.mkdir(parents=True, exist_ok=True)
log_file = log_dir / f"{datetime.now().strftime('%Y-%m-%d')}.log"

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)-8s - %(message)s",
    handlers=[
        logging.FileHandler(log_file, encoding="utf-8"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# === ê¸°ëŠ¥ í•¨ìˆ˜ ===
class ProjectConfig:
    """
    YAML ì„¤ì • íŒŒì¼ì„ ë¡œë“œí•˜ê³ ,
    ${root_dir}, ${dataset_dir}, ${output_dir} ê°™ì€ í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì‹¤ì œ ê²½ë¡œë¡œ ì¹˜í™˜í•œ ë’¤
    í•„ìš”í•œ êµ¬ì„± ë‹¨ìœ„(dataset, output, source, models ë“±)ë¥¼ ë°˜í™˜í•˜ëŠ” í´ë˜ìŠ¤
    """

    def __init__(self, config_path: str):
        """
        [ìƒì„±ì]
        - ì…ë ¥: config_path (str) -> YAML ì„¤ì • íŒŒì¼ ê²½ë¡œ
        - ì¶œë ¥: ì—†ìŒ (í´ë˜ìŠ¤ ë‚´ë¶€ì— config ì €ì¥)
        - ê¸°ëŠ¥: ì„¤ì • íŒŒì¼ ë¡œë“œ ë° ê²½ë¡œ í”Œë ˆì´ìŠ¤í™€ë” ì¹˜í™˜
        """
        self.config_path = Path(config_path)
        self.config = self._load_and_resolve_config()

    def _load_yaml(self) -> dict:
        """
        [ë¹„ê³µê°œ ë©”ì„œë“œ] YAML íŒŒì¼ì„ ì½ì–´ì„œ Python ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        - ì…ë ¥: ì—†ìŒ (self.config_path ì‚¬ìš©)
        - ì¶œë ¥: config (dict)
        """
        with open(self.config_path, "r", encoding="utf-8") as f:
            return yaml.safe_load(f)

    def _resolve_placeholders(self, config: dict, context: dict) -> dict:
        """
        [ë¹„ê³µê°œ ë©”ì„œë“œ] ì„¤ì • ë”•ì…”ë„ˆë¦¬ ë‚´ í”Œë ˆì´ìŠ¤í™€ë”(${var})ë¥¼ ì‹¤ì œ ê°’ìœ¼ë¡œ ì¹˜í™˜
        - ì…ë ¥:
          - config: ì›ë³¸ ì„¤ì • ë”•ì…”ë„ˆë¦¬
          - context: ì¹˜í™˜í•  í‚¤-ê°’ ë§¤í•‘(dict) (ex: {"root_dir": "/home/user/project"})
        - ì¶œë ¥: ì¹˜í™˜ì´ ì™„ë£Œëœ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        """
        pattern = re.compile(r"\$\{([^}]+)\}")  # ${} ì•ˆì˜ ë³€ìˆ˜ë¥¼ ì°¾ëŠ” ì •ê·œì‹ íŒ¨í„´

        def resolve_value(value):
            if isinstance(value, str):
                matches = pattern.findall(value)
                for match in matches:
                    if match in context:
                        value = value.replace(f"${{{match}}}", str(context[match]))
            return value

        def recursive_resolve(obj):
            if isinstance(obj, dict):
                return {k: recursive_resolve(resolve_value(v)) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [recursive_resolve(v) for v in obj]
            else:
                return resolve_value(obj)

        return recursive_resolve(config)

    def _load_and_resolve_config(self) -> dict:
        """
        [ë¹„ê³µê°œ ë©”ì„œë“œ] ì„¤ì • íŒŒì¼ ë¡œë“œ í›„, í”Œë ˆì´ìŠ¤í™€ë” ì¹˜í™˜ê¹Œì§€ ì™„ë£Œ
        - ì…ë ¥: ì—†ìŒ
        - ì¶œë ¥: ì¹˜í™˜ì´ ì™„ë£Œëœ ì „ì²´ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        """
        raw_config = self._load_yaml()
        context = {
            "root_dir": raw_config["project"]["root_dir"],
            "dataset_dir": raw_config["project"]["dataset"]["dataset_dir"],
            "output_dir": raw_config["project"]["output"]["output_dir"],
            "src_dir": raw_config["project"]["source"]["src_dir"]
        }
        return self._resolve_placeholders(raw_config, context)

    # ======= ì™¸ë¶€ì— ì œê³µí•˜ëŠ” ë©”ì„œë“œ =======

    def get_project_config(self) -> dict:
        """
        [ê³µê°œ ë©”ì„œë“œ] project ì „ì²´ ì •ë³´ ë°˜í™˜
        - ì…ë ¥: ì—†ìŒ
        - ì¶œë ¥: project ì„¹ì…˜ (dict)
        """
        return self.config.get("project", {})

    def get_dataset_config(self) -> dict:
        """
        [ê³µê°œ ë©”ì„œë“œ] dataset êµ¬ì„± ì •ë³´ ë°˜í™˜
        - ì…ë ¥: ì—†ìŒ
        - ì¶œë ¥: dataset ì„¹ì…˜ (dict)
        """
        return self.config["project"].get("dataset", {})

    def get_output_config(self) -> dict:
        """
        [ê³µê°œ ë©”ì„œë“œ] output êµ¬ì„± ì •ë³´ ë°˜í™˜
        - ì…ë ¥: ì—†ìŒ
        - ì¶œë ¥: output ì„¹ì…˜ (dict)
        """
        return self.config["project"].get("output", {})

    def get_source_config(self) -> dict:
        """
        [ê³µê°œ ë©”ì„œë“œ] source êµ¬ì„± ì •ë³´ ë°˜í™˜
        - ì…ë ¥: ì—†ìŒ
        - ì¶œë ¥: source ì„¹ì…˜ (dict)
        """
        return self.config["project"].get("source", {})

    def get_models_config(self) -> dict:
        """
        [ê³µê°œ ë©”ì„œë“œ] models ì„¤ì • ì •ë³´ ë°˜í™˜
        - ì…ë ¥: ì—†ìŒ
        - ì¶œë ¥: models ì„¹ì…˜ (dict)
        """
        return self.config.get("models", {})

# === ì‚¬ìš© ì˜ˆì‹œ ===
# if __name__ == "__main__":
#     config = ProjectConfig("config/my_photo_album_3.yaml")
    
#     print("ğŸ“‚ dataset ì •ë³´:", config.get_dataset_config())
#     print("ğŸ“‚ output ì •ë³´:", config.get_output_config())
#     print("ğŸ“‚ source ì •ë³´:", config.get_source_config())
#     print("ğŸ§  models ì •ë³´:", config.get_models_config())
    
# def load_config(config_path: str) -> dict:
#     """YAML ì„¤ì • íŒŒì¼ ë¡œë“œ"""
#     try:
#         with open(config_path, "r", encoding="utf-8") as f:
#             config = yaml.safe_load(f)
#         return config
#     except Exception as e:
#         logger.critical(f"ì„¤ì • íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {e}")
#         raise

def resolve_path_placeholders(
    config_data: Union[Dict[str, Any], list],
    placeholder: str,
    base_path: Path
) -> Union[Dict[str, Any], list]:
    """
    ë”•ì…”ë„ˆë¦¬ë‚˜ ë¦¬ìŠ¤íŠ¸ ë‚´ì˜ ë¬¸ìì—´ ê°’ì—ì„œ í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì£¼ì–´ì§„ ê²½ë¡œë¡œ ì¬ê·€ì ìœ¼ë¡œ ì¹˜í™˜í•©ë‹ˆë‹¤.
    ì›ë³¸ ë°ì´í„° êµ¬ì¡°ë¥¼ ì§ì ‘ ìˆ˜ì •í•©ë‹ˆë‹¤(in-place).

    Args:
        config_data: ì²˜ë¦¬í•  ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸.
        placeholder: ì¹˜í™˜í•  í”Œë ˆì´ìŠ¤í™€ë” ë¬¸ìì—´ (ì˜ˆ: "${base_dir}").
        base_path: í”Œë ˆì´ìŠ¤í™€ë” ëŒ€ì‹  ì‚¬ìš©í•  Path ê°ì²´.

    Returns:
        ìˆ˜ì •ëœ config_data (in-place ìˆ˜ì •ë¨).
    """
    if isinstance(config_data, dict):
        for key, value in config_data.items():
            if isinstance(value, str):
                original_value = value
                # Path ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ replace í•¨ìˆ˜ì— ì‚¬ìš©
                updated_value = value.replace(placeholder, str(base_path))
                if updated_value != original_value:
                    logger.debug(f"  Replacing placeholder in '{key}': '{original_value}' -> '{updated_value}'")
                    config_data[key] = updated_value
            elif isinstance(value, (dict, list)):
                # í•˜ìœ„ ë”•ì…”ë„ˆë¦¬ë‚˜ ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•´ ì¬ê·€ í˜¸ì¶œ
                resolve_path_placeholders(value, placeholder, base_path)
    elif isinstance(config_data, list):
        for i, item in enumerate(config_data):
            if isinstance(item, str):
                original_item = item
                updated_item = item.replace(placeholder, str(base_path))
                if updated_item != original_item:
                    logger.debug(f"  Replacing placeholder in list index {i}: '{original_item}' -> '{updated_item}'")
                    config_data[i] = updated_item
            elif isinstance(item, (dict, list)):
                # ë¦¬ìŠ¤íŠ¸ ë‚´ì˜ ë”•ì…”ë„ˆë¦¬ë‚˜ ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•´ ì¬ê·€ í˜¸ì¶œ
                resolve_path_placeholders(item, placeholder, base_path)
    return config_data # ìˆ˜ì •ëœ ë°ì´í„° êµ¬ì¡° ë°˜í™˜ (ì‹¤ì œë¡œëŠ” in-place ìˆ˜ì •)


# 0. detect_faces_with_polygon Face Detector ì‚¬ìš©

def detect_faces_with_polygon(image: Image.Image, min_confidence: float = 0.5) -> List[Dict]:
    """ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ ë‹¤ê°í˜• ê²€ì¶œ"""
    image_np = np.array(image.convert("RGB"))
    height, width = image_np.shape[:2]
    faces = []

    with ã…Š(static_image_mode=True, max_num_faces=10, refine_landmarks=True,
                                min_detection_confidence=min_confidence) as face_mesh:
        results = face_mesh.process(image_np)
        if not results.multi_face_landmarks:
            return []

        for face_landmarks in results.multi_face_landmarks:
            indices = list(range(0, 17)) + list(range(68, 83))
            polygon = [{"x": round(face_landmarks.landmark[i].x * width, 2),
                        "y": round(face_landmarks.landmark[i].y * height, 2)} for i in indices]
            faces.append({"score": 1.0, "polygon": polygon})

    return faces


# 1. MediaPipe Face Detection ì‚¬ìš©

# MediaPipe Face Detection ì´ˆê¸°í™” (ë£¨í”„ ë°–ì—ì„œ í•œ ë²ˆë§Œ ì‹¤í–‰ ê¶Œì¥)
mp_face_detection = mp.solutions.face_detection
# face_detector = mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5) # model_selection=0ì€ ë‹¨ê±°ë¦¬, 1ì€ ì¥ê±°ë¦¬

def detect_faces_mp_detection(image: Image.Image, min_confidence: float = 0.5) -> List[Dict]:
    """MediaPipe Face Detectionì„ ì´ìš©í•œ ì–¼êµ´ ê²€ì¶œ"""
    # FaceDetection ê°ì²´ëŠ” with ë¬¸ì„ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ë¯¸ë¦¬ ìƒì„±ëœ ê°ì²´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œë¥¼ ìœ„í•´ í•¨ìˆ˜ ë‚´ì—ì„œ ìƒì„± (ë¹„íš¨ìœ¨ì )
    with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=min_confidence) as face_detector:
        image_np = np.array(image.convert("RGB"))
        height, width = image_np.shape[:2]
        results = face_detector.process(image_np)
        faces = []

        if results.detections:
            for detection in results.detections:
                score = detection.score[0] # ê²€ì¶œ ì‹ ë¢°ë„
                box = detection.location_data.relative_bounding_box
                # ìƒëŒ€ ì¢Œí‘œë¥¼ ì ˆëŒ€ ì¢Œí‘œë¡œ ë³€í™˜
                x = int(box.xmin * width)
                y = int(box.ymin * height)
                w = int(box.width * width)
                h = int(box.height * height)

                # ê²½ê³„ ìƒìë¥¼ ë‹¤ê°í˜•ìœ¼ë¡œ í‘œí˜„ (ì‚¬ê°í˜•)
                polygon = [{"x": x, "y": y}, {"x": x + w, "y": y},
                           {"x": x + w, "y": y + h}, {"x": x, "y": y + h}]

                faces.append({
                    "score": round(float(score), 4),
                    "polygon": polygon,
                    "bounding_box": {"x": x, "y": y, "width": w, "height": h} # ê²½ê³„ ìƒì ì •ë³´ë„ ì¶”ê°€
                })
        return faces

# 2. OpenCV Haar Cascades ì‚¬ìš©

# Haar Cascade ëª¨ë¸ ë¡œë“œ (ë£¨í”„ ë°–ì—ì„œ í•œ ë²ˆë§Œ ì‹¤í–‰ ê¶Œì¥)
# cascade_path = Path("my_photo_album_3/config/haarcascade_frontalface_default.xml") # ì‹¤ì œ ê²½ë¡œ í™•ì¸
# if cascade_path.exists():
#     face_cascade = cv2.CascadeClassifier(str(cascade_path))
# else:
#     # ì˜¤ë¥˜ ì²˜ë¦¬
#     face_cascade = None

def detect_faces_haar(image: Image.Image, face_cascade: cv2.CascadeClassifier, scaleFactor: float = 1.1, minNeighbors: int = 5, minSize: tuple = (30, 30)) -> List[Dict]:
    """OpenCV Haar Cascadeë¥¼ ì´ìš©í•œ ì–¼êµ´ ê²€ì¶œ"""
    if face_cascade is None:
        logger.error("Haar Cascade ë¶„ë¥˜ê¸°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return []

    image_np = np.array(image.convert("L")) # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
    faces_rects = face_cascade.detectMultiScale(image_np,
                                                scaleFactor=scaleFactor,
                                                minNeighbors=minNeighbors,
                                                minSize=minSize)
    faces = []
    for (x, y, w, h) in faces_rects:
        # HaarëŠ” ì‹ ë¢°ë„ ì ìˆ˜ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŒ
        # ê²½ê³„ ìƒìë¥¼ ë‹¤ê°í˜•ìœ¼ë¡œ í‘œí˜„ (ì‚¬ê°í˜•)
        polygon = [{"x": x, "y": y}, {"x": x + w, "y": y},
                   {"x": x + w, "y": y + h}, {"x": x, "y": y + h}]
        faces.append({
            "score": 1.0, # ì„ì˜ ì ìˆ˜
            "polygon": polygon,
            "bounding_box": {"x": x, "y": y, "width": w, "height": h}
        })
    return faces

# ì‚¬ìš© ì˜ˆì‹œ:
# config = load_config(...)
# cascade_path = Path(config["project"]["config"]["haar_cascade_path"]) # ì„¤ì •ì—ì„œ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
# if cascade_path.exists():
#    face_cascade_classifier = cv2.CascadeClassifier(str(cascade_path))
#    # ... ì´ë¯¸ì§€ ë£¨í”„ ë‚´ ...
#    faces = detect_faces_haar(img, face_cascade_classifier)

# 3. OpenCV DNN Face Detector ì‚¬ìš©

# DNN ëª¨ë¸ ë¡œë“œ (ë£¨í”„ ë°–ì—ì„œ í•œ ë²ˆë§Œ ì‹¤í–‰ ê¶Œì¥)
# prototxt_path = Path("path/to/deploy.prototxt")
# model_path = Path("path/to/res10_300x300_ssd_iter_140000.caffemodel")
# if prototxt_path.exists() and model_path.exists():
#     net = cv2.dnn.readNetFromCaffe(str(prototxt_path), str(model_path))
# else:
#     # ì˜¤ë¥˜ ì²˜ë¦¬
#     net = None

def detect_faces_dnn(image: Image.Image, net: cv2.dnn_Net, confidence_threshold: float = 0.5) -> List[Dict]:
    """OpenCV DNNì„ ì´ìš©í•œ ì–¼êµ´ ê²€ì¶œ"""
    if net is None:
         logger.error("OpenCV DNN ë„¤íŠ¸ì›Œí¬ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
         return []

    image_np = np.array(image.convert("RGB"))
    (h, w) = image_np.shape[:2]
    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
    blob = cv2.dnn.blobFromImage(cv2.resize(image_np, (300, 300)), 1.0,
                                (300, 300), (104.0, 177.0, 123.0))

    net.setInput(blob)
    detections = net.forward()
    faces = []

    for i in range(0, detections.shape[2]):
        confidence = detections[0, 0, i, 2]

        if confidence > confidence_threshold:
            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
            (startX, startY, endX, endY) = box.astype("int")
            width_box = endX - startX
            height_box = endY - startY

            # ê²½ê³„ ìƒìë¥¼ ë‹¤ê°í˜•ìœ¼ë¡œ í‘œí˜„ (ì‚¬ê°í˜•)
            polygon = [{"x": startX, "y": startY}, {"x": endX, "y": startY},
                       {"x": endX, "y": endY}, {"x": startX, "y": endY}]

            faces.append({
                "score": round(float(confidence), 4),
                "polygon": polygon,
                "bounding_box": {"x": startX, "y": startY, "width": width_box, "height": height_box}
            })
    return faces

# ì‚¬ìš© ì˜ˆì‹œ:
# config = load_config(...)
# prototxt = Path(config["models"]["dnn_prototxt_path"]) # ì„¤ì •ì—ì„œ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
# model = Path(config["models"]["dnn_model_path"])
# if prototxt.exists() and model.exists():
#     dnn_net = cv2.dnn.readNetFromCaffe(str(prototxt), str(model))
#     # ... ì´ë¯¸ì§€ ë£¨í”„ ë‚´ ...
#     faces = detect_faces_dnn(img, dnn_net, min_conf)

# 4. Dlib HOG ì‚¬ìš©

# Dlib HOG ê²€ì¶œê¸° ë¡œë“œ (ë£¨í”„ ë°–ì—ì„œ í•œ ë²ˆë§Œ ì‹¤í–‰ ê¶Œì¥)
# hog_face_detector = dlib.get_frontal_face_detector()

def detect_faces_dlib_hog(image: Image.Image, detector: dlib.fhog_object_detector) -> List[Dict]:
    """Dlib HOGë¥¼ ì´ìš©í•œ ì–¼êµ´ ê²€ì¶œ"""
    if detector is None:
        logger.error("Dlib HOG ê²€ì¶œê¸°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return []

    image_np = np.array(image.convert("RGB")) # Dlibì€ RGB ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©
    dets = detector(image_np, 1) # ë‘ ë²ˆì§¸ ì¸ìëŠ” ì—…ìƒ˜í”Œë§ íšŸìˆ˜
    faces = []

    for d in dets:
        x = d.left()
        y = d.top()
        w = d.width()
        h = d.height()

        # ê²½ê³„ ìƒìë¥¼ ë‹¤ê°í˜•ìœ¼ë¡œ í‘œí˜„ (ì‚¬ê°í˜•)
        polygon = [{"x": x, "y": y}, {"x": x + w, "y": y},
                   {"x": x + w, "y": y + h}, {"x": x, "y": y + h}]

        faces.append({
            "score": 1.0, # HOGëŠ” ì‹ ë¢°ë„ ì ìˆ˜ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŒ
            "polygon": polygon,
            "bounding_box": {"x": x, "y": y, "width": w, "height": h}
        })
    return faces


# ì‚¬ìš© ì˜ˆì‹œ:
# hog_detector = dlib.get_frontal_face_detector()
# # ... ì´ë¯¸ì§€ ë£¨í”„ ë‚´ ...
# faces = detect_faces_dlib_hog(img, hog_detector)


# 5. Dlib CNN ì‚¬ìš©

# Dlib CNN ëª¨ë¸ ë¡œë“œ (ë£¨í”„ ë°–ì—ì„œ í•œ ë²ˆë§Œ ì‹¤í–‰ ê¶Œì¥)
# cnn_model_path = Path("path/to/mmod_human_face_detector.dat") # ì‹¤ì œ ê²½ë¡œ í™•ì¸
# if cnn_model_path.exists():
#     cnn_face_detector = dlib.cnn_face_detection_model_v1(str(cnn_model_path))
# else:
#     # ì˜¤ë¥˜ ì²˜ë¦¬
#     cnn_face_detector = None

def detect_faces_dlib_cnn(image: Image.Image, detector: dlib.cnn_face_detection_model_v1, confidence_threshold: float = 0.5) -> List[Dict]:
    """Dlib CNNì„ ì´ìš©í•œ ì–¼êµ´ ê²€ì¶œ"""
    if detector is None:
        logger.error("Dlib CNN ê²€ì¶œê¸°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return []

    image_np = np.array(image.convert("RGB"))
    dets = detector(image_np, 1) # ë‘ ë²ˆì§¸ ì¸ìëŠ” ì—…ìƒ˜í”Œë§ íšŸìˆ˜
    faces = []

    for d in dets:
        confidence = d.confidence
        if confidence >= confidence_threshold:
            rect = d.rect
            x = rect.left()
            y = rect.top()
            w = rect.width()
            h = rect.height()

            # ê²½ê³„ ìƒìë¥¼ ë‹¤ê°í˜•ìœ¼ë¡œ í‘œí˜„ (ì‚¬ê°í˜•)
            polygon = [{"x": x, "y": y}, {"x": x + w, "y": y},
                       {"x": x + w, "y": y + h}, {"x": x, "y": y + h}]

            faces.append({
                "score": round(float(confidence), 4),
                "polygon": polygon,
                "bounding_box": {"x": x, "y": y, "width": w, "height": h}
            })
    return faces

# ì‚¬ìš© ì˜ˆì‹œ:
# config = load_config(...)
# cnn_path = Path(config["models"]["dlib_cnn_model_path"]) # ì„¤ì •ì—ì„œ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
# if cnn_path.exists():
#     cnn_detector = dlib.cnn_face_detection_model_v1(str(cnn_path))
#     # ... ì´ë¯¸ì§€ ë£¨í”„ ë‚´ ...
#     faces = detect_faces_dlib_cnn(img, cnn_detector, min_conf)


# 6. MTCNN ì‚¬ìš©

# MTCNN ê²€ì¶œê¸° ë¡œë“œ (ë£¨í”„ ë°–ì—ì„œ í•œ ë²ˆë§Œ ì‹¤í–‰ ê¶Œì¥)
# detector = MTCNN()

def detect_faces_mtcnn(image: Image.Image, detector: MTCNN, confidence_threshold: float = 0.9) -> List[Dict]:
    """MTCNNì„ ì´ìš©í•œ ì–¼êµ´ ê²€ì¶œ"""
    if detector is None:
        logger.error("MTCNN ê²€ì¶œê¸°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return []

    image_np = np.array(image.convert("RGB"))
    results = detector.detect_faces(image_np)
    faces = []

    for result in results:
        confidence = result['confidence']
        if confidence >= confidence_threshold:
            x, y, w, h = result['box']

            # ê²½ê³„ ìƒìë¥¼ ë‹¤ê°í˜•ìœ¼ë¡œ í‘œí˜„ (ì‚¬ê°í˜•)
            polygon = [{"x": x, "y": y}, {"x": x + w, "y": y},
                       {"x": x + w, "y": y + h}, {"x": x, "y": y + h}]

            faces.append({
                "score": round(float(confidence), 4),
                "polygon": polygon,
                "bounding_box": {"x": x, "y": y, "width": w, "height": h},
                "keypoints": result['keypoints'] # MTCNNì€ ì£¼ìš” íŠ¹ì§•ì ë„ ì œê³µ
            })
    return faces

# ì‚¬ìš© ì˜ˆì‹œ:
# mtcnn_detector = MTCNN()
# # ... ì´ë¯¸ì§€ ë£¨í”„ ë‚´ ...
# faces = detect_faces_mtcnn(img, mtcnn_detector, min_conf)


def compute_image_hash(image) -> str:
    """
    SHA-256 í•´ì‹œë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
    ì…ë ¥ (in):
        - image: PIL.Image.Image ê°ì²´ ë˜ëŠ” numpy.ndarray ê°ì²´
    ì¶œë ¥ (out):
        - str: SHA-256 í•´ì‹œ ë¬¸ìì—´
    ê¸°ëŠ¥:
        - ì´ë¯¸ì§€ê°€ PIL ê°ì²´ê°€ ì•„ë‹ˆë©´ ìë™ ë³€í™˜ ì‹œë„
        - PIL Image ê°ì²´ì—ì„œ tobytes()ë¡œ í•´ì‹œ ê³„ì‚°
    """
    if isinstance(image, np.ndarray):
        # NumPy ë°°ì—´ì´ë©´ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
        image = Image.fromarray(image)
    elif not isinstance(image, Image.Image):
        # PIL.Image.Image íƒ€ì…ì´ ì•„ë‹ˆë©´ ì˜¤ë¥˜ ë°œìƒ
        raise TypeError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…ì…ë‹ˆë‹¤: {type(image)}")

    return hashlib.sha256(image.tobytes()).hexdigest()
def save_face_json_with_polygon(image_path: Path, image_hash: str, faces: List[Dict], output_path: Path) -> None:
    """ì–¼êµ´ ê²€ì¶œ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    output_path.parent.mkdir(parents=True, exist_ok=True)
    json_data = {
        "image_name": image_path.name,
        "image_path": str(image_path.resolve()),
        "image_hash": image_hash,
        "faces": faces
    }
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(json_data, f, indent=2, ensure_ascii=False)

def process_images(config: ProjectConfig):
    """ì„¤ì •ì— ë”°ë¼ ì´ë¯¸ì§€ ì²˜ë¦¬ ì „ì²´ íë¦„"""
    models_info = config.get_project_config()
    min_conf = float(models_info.get("min_detection_confidence", 0.5))

    detected_list = []
    undetected_list = []
    fail_list = []

    if not raw_image_dir.exists():
        logger.error(f"âŒ ì´ë¯¸ì§€ í´ë” ì—†ìŒ: {raw_image_dir}")
        return

    # ì§€ì›í•˜ëŠ” ì´ë¯¸ì§€ í™•ì¥ì ëª©ë¡ (ì„¤ì • íŒŒì¼ì—ì„œ ê°€ì ¸ì˜¤ë„ë¡ ìˆ˜ì • ê°€ëŠ¥)
    supported_extensions = {ext.lower() for ext in config.get("models", {}).get("supported_image_extensions", [".jpg", ".jpeg", ".png"])}
    image_files = [p for p in raw_image_dir.glob("**/*") if p.is_file() and p.suffix.lower() in supported_extensions]
    logger.info(f"ğŸ” ì´ {len(image_files)}ì¥ì˜ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    try:
        # with ë¬¸ì„ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ íŒŒì¼ì„ ë™ì‹œì— ì•ˆì „í•˜ê²Œ ì—½ë‹ˆë‹¤.
        with open(detected_list_path, 'a', encoding='utf-8') as detected_file, \
             open(undetect_list_path, 'a', encoding='utf-8') as undetected_file, \
             open(failed_list_path, 'a', encoding='utf-8') as fail_file:

            # ì²˜ë¦¬ ê²°ê³¼ ì¹´ìš´í„°
            detected_count = 0
            undetected_count = 0
            fail_count = 0

            for img_path in image_files:
                try:
                    # with ë¬¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ íŒŒì¼ í•¸ë“¤ ìë™ ê´€ë¦¬
                    # PIL.Image.open(), Pillow (PIL.Image)ë¼ì´ë¸ŒëŸ¬ë¦¬
                    with Image.open(img_path) as img:       #RGB (Red-Green-Blue)
                        img_rgb = img.convert("RGB") # RGBë¡œ ë³€í™˜
                        img_hash = compute_image_hash(img_rgb)
                        faces = detect_faces_with_polygon(img_rgb, min_conf)

                    if faces:
                        # JSON íŒŒì¼ ê²½ë¡œ ìƒì„± (ì›ë³¸ê³¼ ë™ì¼í•œ í•˜ìœ„ í´ë” êµ¬ì¡° ìœ ì§€)
                        relative_path = img_path.relative_to(raw_image_dir)
                        json_path = raw_jsons_dir / relative_path.with_suffix(".json")
                        json_path.parent.mkdir(parents=True, exist_ok=True) # JSON ì €ì¥ í´ë” ìƒì„±

                        save_face_json_with_polygon(img_path, img_hash, faces, json_path)
                        # --- íŒŒì¼ì— ì§ì ‘ ì“°ê¸° ---
                        detected_file.write(f"{img_path.resolve()}\n")
                        detected_count += 1
                        logger.info(f"âœ… ì–¼êµ´ ê²€ì¶œ ì„±ê³µ: {img_path.name}")
                    else:
                        # --- íŒŒì¼ì— ì§ì ‘ ì“°ê¸° ---
                        undetected_file.write(f"{img_path.resolve()}\n")
                        undetected_count += 1
                        logger.info(f"âš ï¸ ì–¼êµ´ ê²€ì¶œ ì‹¤íŒ¨: {img_path.name}")

                except FileNotFoundError:
                    logger.warning(f"âš ï¸ ì²˜ë¦¬ ì¤‘ ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ (ì´ë™/ì‚­ì œë˜ì—ˆì„ ìˆ˜ ìˆìŒ): {img_path}")
                    # --- íŒŒì¼ì— ì§ì ‘ ì“°ê¸° ---
                    fail_file.write(f"{img_path.resolve()} (File not found during processing)\n")
                    fail_count += 1
                except Exception as e:
                    logger.warning(f"âš ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {img_path} ({e})")
                    # --- íŒŒì¼ì— ì§ì ‘ ì“°ê¸° ---
                    fail_file.write(f"{img_path.resolve()} (Error: {e})\n")
                    fail_count += 1
                    # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë‹¤ìŒ ì´ë¯¸ì§€ë¡œ ë„˜ì–´ê° (continueëŠ” í•„ìš” ì—†ìŒ, ë£¨í”„ê°€ ê³„ì†ë¨)

            # --- ìµœì¢… ê²°ê³¼ ìš”ì•½ ë¡œê·¸ ---
            logger.info(f"--- ì²˜ë¦¬ ì™„ë£Œ ---")
            logger.info(f"âœ… ì–¼êµ´ ê²€ì¶œ ì„±ê³µ: {detected_count} ê±´")
            logger.info(f"âš ï¸ ì–¼êµ´ ê²€ì¶œ ì‹¤íŒ¨: {undetected_count} ê±´")
            logger.info(f"âŒ ì²˜ë¦¬ ì˜¤ë¥˜ ë°œìƒ: {fail_count} ê±´")
            logger.info(f"ğŸ“„ ê²°ê³¼ ëª©ë¡ íŒŒì¼ ìœ„ì¹˜:")
            logger.info(f"   - ì„±ê³µ: {detected_list_path}")
            logger.info(f"   - ì‹¤íŒ¨(ë¯¸ê²€ì¶œ): {undetect_list_path}")
            logger.info(f"   - ì˜¤ë¥˜: {failed_list_path}")

    except IOError as e:
        logger.critical(f"ê²°ê³¼ ëª©ë¡ íŒŒì¼ ì—´ê¸°/ì“°ê¸° ì˜¤ë¥˜: {e}")
    except Exception as e:
        logger.critical(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")



# === ë©”ì¸ ì‹¤í–‰ ===

if __name__ == "__main__":
    # 0. ê¸°ì¦˜ ë‚´ê°€ ì¼í•˜ëŠ” ê³³ì€"
    direction_dir = os.getcwd()
    print(f"ì§€ê¸ˆ ì¥”ê³„ì„œ ê³„ì‹ ê³³(direction_dir) : {direction_dir}")
    
    worker_path_obj = Path(__file__).resolve()
    project_root_path = worker_path_obj.parent.parent
    print(f"ì§€ê¸ˆ ì¼ê¾¼ì´ ì¼í•˜ëŠ”ê³³(worker_dir_name)  : {project_root_path}")

    if len(sys.argv) > 1:
        config_path = sys.argv[1]
    else:
        config_path = f"{project_root_path}/config/{project_root_path.name}.yaml"
        print(f"ì„¤ì • íŒŒì¼ ê²½ë¡œ: {config_path}")

    try:
#     config = ProjectConfig("config/my_photo_album_3.yaml")
        config = ProjectConfig(config_path)
        logger.info(f"Loaded config from: {config_path}")
    except Exception as e:
        logger.critical(f"Failed to load config: {config_path} - {e}")
        return # ì„¤ì • ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì¢…ë£Œ
    try:
        process_images(config)
    except FileNotFoundError:
        # load_configì—ì„œ ë°œìƒí•œ FileNotFoundError ì²˜ë¦¬
        logging.critical("ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ë‹¨: ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except Exception as e:
        logging.critical(f"ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        sys.exit(1)
