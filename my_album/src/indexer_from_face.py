# src/face_indexer_from_face.py

# í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import os
import sys
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Tuple, Set

# ì‚¬ìš©ì ì •ì˜ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from my_utils.config_utils.SimpleLogger import logger, calc_digit_number, get_argument, visual_length
    from my_utils.config_utils.configger import configger
    from my_utils.photo_utils.object_utils import rotate_image_if_needed, compute_sha256, load_json, save_object_json_with_polygon, save_cropped_face_image, read_json_with_config_keys, write_json_from_config
except ImportError as e:
    # ì‹¤ì œ ë°œìƒí•œ ì˜ˆì™¸ eë¥¼ ì¶œë ¥í•˜ì—¬ ì›ì¸ íŒŒì•…
    print(f"ëª¨ë“ˆ ì„í¬íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    print(f"ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´:")
    import traceback
    traceback.print_exc() # ì „ì²´ íŠ¸ë ˆì´ìŠ¤ë°± ì¶œë ¥ (ê°œë°œ ë‹¨ê³„ì—ì„œ ìœ ìš©)
    sys.exit(1)

# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
try:
    import cv2 # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹œ ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ ë“±ì„ ì°¸ì¡°í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìœ ì§€ (ì§ì ‘ ì‚¬ìš© ì•ˆ í•  ìˆ˜ë„ ìˆìŒ)
    import dlib # dlib ëª¨ë¸ ë¡œë“œ ë¶€ë¶„ì€ ìœ ì§€ (í–¥í›„ ë‹¤ë¥¸ ê¸°ëŠ¥ì— í•„ìš”í•  ìˆ˜ ìˆìŒ)
    import numpy as np
    import faiss
except ImportError as e:
    logger.error(f"í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
    logger.info("Poetry í™˜ê²½ì—ì„œ 'poetry install'ì„ ì‹¤í–‰í•˜ì—¬ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

# --- ì „ì—­ ë³€ìˆ˜: í†µê³„ìš© ë³€ìˆ˜ ì‚¬ìš©ì„ ìœ„í•´í•´ ---
DEFAULT_STATUS_TEMPLATE  = {
    "total_input_found":         {"value": 0,  "msg": "ì´ ì…ë ¥ íŒŒì¼ ìˆ˜ (ì§€ì› í™•ì¥ì ê¸°ì¤€)"},
    "error_input_file_read":        {"value": 0,  "msg": "ì…ë ¥ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ìˆ˜"},
    "req_process_count":         {"value": 0,  "msg": "ì´ ì²˜ë¦¬ ìš”ì²­ íŒŒì¼ ìˆ˜"},
    "error_extension":   {"value": 0,  "msg": "ì§€ì›ë˜ì§€ ì•ŠëŠ” í™•ì¥ìë¡œ ê±´ë„ˆë›´ íŒŒì¼ ìˆ˜"},
    "error_image_rotation":          {"value": 0,  "msg": "ì´ë¯¸ì§€ íšŒì „ì¤‘ ì˜¤ë¥˜ ë°œìƒ íŒŒì¼ ìˆ˜"},
    "error_target_file_get":        {"value": 0,  "msg": "ì²˜ë¦¬ëŒ€ìƒ(image or json) íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ìˆ˜"},
    "error_input_file_process":        {"value": 0,  "msg": "ì…ë «íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ìˆ˜"},
    "request_embedding":        {"value": 0,  "msg": "embdding ìš”ì²­ ìˆ˜"},
    "error_embedding_empty_target":        {"value": 0,  "msg": "embdding ì˜¤ë¥˜ ìˆ˜ - ì²˜ë¦¬ëŒ€ìƒì´ ì—†ìŒ"},
    "error_embeddings_array":        {"value": 0,  "msg": "embdding ì˜¤ë¥˜ ìˆ˜ - ë¹ˆ ì„ë² ë”©ì¸"},
    "error_embeddings_none_config":        {"value": 0,  "msg": "embdding ì˜¤ë¥˜ ìˆ˜ - ì„¤ì ˆê°’ì´ ì—†ìŒ"},
    "error_embeddings_deff_config":        {"value": 0,  "msg": "embdding ì˜¤ë¥˜ ìˆ˜ - ì„¤ì ˆê°’ê³¼ ë‹¤ë¦„"},
    "error_embeddings_deff_spec":        {"value": 0,  "msg": "embdding ì˜¤ë¥˜ ìˆ˜ - ê·œê²©-shapì´ ë‹¤ë¦„"},
    "error_embeddings_none_learn":        {"value": 0,  "msg": "embdding ì˜¤ë¥˜ ìˆ˜ - í•™ìŠµê°’ì´ ì—†ìŒ"},
    "error_embeddings_deff_drainage":        {"value": 0,  "msg": "embdding ì˜¤ë¥˜ ìˆ˜ - ë°°ìˆ˜ê°€ ì•„ë‹˜"},
    "error_embeddings_objebt_gen":        {"value": 0,  "msg": "embdding ì˜¤ë¥˜ ìˆ˜ - ê°ì²´ìƒì„±ì‹¤íŒ¨"},
    "error_embeddings_read_index":        {"value": 0,  "msg": "embdding ì˜¤ë¥˜ ìˆ˜ - ê°ì²´ìƒì„±ì‹¤íŒ¨"},
    "request_save_index":        {"value": 0,  "msg": "ì¸ë±ìŠ¤ ì €ì¥ ìš”ì²­ ìˆ˜"},
    "total_object_count":      {"value": 0,  "msg": "ê²€ì¶œëœ ì´ ê°ì²´ ìˆ˜"},
    "detection_object_file":     {"value": 0,  "msg": "ê°ì²´ê°€ ê²€ì¶œëœ íŒŒì¼ ìˆ˜"},
    "get_object_crop":           {"value": 0,  "msg": "ê°ì²´ê°€ ê²€ì¶œëœ ê°ì²´ ìˆ˜"},
    "error_object_crop":           {"value": 0,  "msg": "ê°ì²´ê°€ ê²€ì¶œëœ ê°ì²´ ìˆ˜"},
    "error_object_bbox":           {"value": 0,  "msg": "ê°ì²´ê°€ ê²€ì¶œëœ ê°ì²´ ìˆ˜"},
    "error_object_bbox_cnt":           {"value": 0,  "msg": "ê°ì²´ê°€ ê²€ì¶œëœ ê°ì²´ ìˆ˜"},
    "error_object_bbox_posit":           {"value": 0,  "msg": "ê°ì²´ê°€ ê²€ì¶œëœ ê°ì²´ ìˆ˜"},
    "undetection_object":   {"value": 0,  "msg": "ê°ì²´ê°€ ê²€ì¶œë˜ì§€ ì•Šì€ íŒŒì¼ ìˆ˜"},
    "error_copied_input_file": {"value": 0, "msg": "ì˜¤ë¥˜ë°œìƒ ì‰ã…‚ë ¥íŒ¡ã„¹ ë³´ê´€ì‹œ ì‹¤íŒ¨ ìˆ˜"},
    "detect_faces_in_object":    {"value": 0,  "msg": "ê°ì²´ì—ì„œ ì–¼êµ´ê²€ì¶œì„ ì„±ê³µí•œ ìˆ˜"},
    "error_faces_in_object":    {"value": 0,  "msg": "ê°ì²´ì—ì„œ ì–¼êµ´ê²€ì¶œì„ ì„±ê³µí•œ ìˆ˜"},
    "unmatched_object_number":   {"value": 0,  "msg": "ê²€ì¶œ ëŒ€ìƒ objectìˆ˜ì™€ ê²€ì¶œí•œ objectì˜ ìˆ˜ê°€ ë‹¤ë¥¸ íŒŒì¼ìˆ˜"},
    "total_output_files":        {"value": 0,  "msg": "ì´ ì¶œë ¥ íŒŒì¼ìˆ˜"},
    "read_input_files_success":          {"value": 0,  "msg": "ì½ì€ ì…ë ¥ íŒŒì¼ ìˆ˜ (detect_object ê¸°ì¤€)"},
    "read_input_files_error":          {"value": 0,  "msg": "ì½ì€ ì…ë ¥ íŒŒì¼ ìˆ˜ (detect_object ê¸°ì¤€)"},
    "files_json_load":           {"value": 0,  "msg": "JSON ì •ë³´ ì½ì€ íŒŒì¼ ìˆ˜"},
    "files_json_update":         {"value": 0,  "msg": "JSON íŒŒì¼ ë§ì”Œìš°ê¸° ì„±ê³µ íŒŒì¼ ìˆ˜"},
    "error_json_update":         {"value": 0,  "msg": "JSON íŒŒì¼ ë§ì”Œìš°ê¸° ì„±ê³µ íŒŒì¼ ìˆ˜"},
    "get_image_path_in_json":    {"value": 0,  "msg": "IMAGE íŒŒì¼ ê²½ë¡œ ê°€ì ¸ì˜¨ íŒŒì¼ ìˆ˜"},
    "detection_object_file":     {"value": 0,  "msg": "ê°ì²´ê°€ ê²€ì¶œëœ íŒŒì¼ ìˆ˜"},
    "undetected_image_copied_success": {"value": 0, "msg": "ë¯¸ê²€ì¶œ ì´ë¯¸ì§€ ë³µì‚¬ ì„±ê³µ ìˆ˜"},
    "undetected_image_copied_error": {"value": 0, "msg": "ë¯¸ê²€ì¶œ ì´ë¯¸ì§€ ë³µì‚¬ ì‹¤íŒ¨ ìˆ˜"},
    "undetection_object_file":   {"value": 0,  "msg": "ê°ì²´ê°€ ê²€ì¶œë˜ì§€ ì•Šì€ íŒŒì¼ ìˆ˜"},
    "num_detected_objects":      {"value": 0,  "msg": "ê²€ì¶œëœ ì´ ê°ì²´ ìˆ˜"},
    "files_object_crop":         {"value": 0,  "msg": "ê°ì²´ê°€ ìˆëŠ” íŒŒì¼ ìˆ˜"},
    "error_faild_file_backup":        {"value": 0,  "msg": "ì½ì„ë•Œ ì˜¤ë¥˜ê°€ ë‚œ ì…ë ¥ íŒŒì¼ì„ ë³´ê´€í•˜ëŠ”ë° ì˜¤ë¥˜ë°œìƒ ìˆ˜"},
    "files_skipped_extension":   {"value": 0,  "msg": "ì§€ì›ë˜ì§€ ì•ŠëŠ” í™•ì¥ìë¡œ ê±´ë„ˆë›´ íŒŒì¼ ìˆ˜"},
    "files_processed_for_log":   {"value": 0,  "msg": "ë¡œê·¸ìš©ìœ¼ë¡œ ì²˜ë¦¬ ì‹œë„í•œ íŒŒì¼ ìˆ˜"}, # Not for final stats display usually
    "files_processed_main_error":{"value": 0,  "msg": "ë©”ì¸ ë£¨í”„ì—ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ íŒŒì¼ ìˆ˜"}
} 

# ì´ ìŠ¤í¬ë¦½íŠ¸ì—ì„œëŠ” ì§ì ‘ ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ, ì„¤ì • íŒŒì¼ ë¡œì§ ë“±ì—ì„œ ì°¸ì¡°í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.
# ë˜ëŠ”, dlib ëª¨ë¸ ë¡œë“œ ê´€ë ¨ ë¶€ë¶„ì„ ì™„ì „íˆ ì œê±°í•´ë„ ë©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ì¼ë‹¨ ìœ ì§€í•©ë‹ˆë‹¤.
def load_dlib_models(cfg_obj) -> dict | None:
    """
    dlibì˜ ì–¼êµ´ ì¸ì‹ ê´€ë ¨ ëª¨ë¸ íŒŒì¼ë“¤ì„ ë¡œë“œí•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        cfg_obj (configger): ì„¤ì • íŒŒì¼ ë‚´ìš©ì„ ë‹´ê³  ìˆëŠ” configger ê°ì²´.

    Returns:
        dict | None: ë¡œë“œëœ dlib ëª¨ë¸ ê°ì²´ë“¤ì„ ë‹´ì€ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” ë¡œë“œ ì‹¤íŒ¨ ì‹œ None.
                     ë°˜í™˜ë˜ëŠ” ë”•ì…”ë„ˆë¦¬ í‚¤: 'face_detector', 'shape_predictor', 'face_recognizer'
    """
    models_key_str = 'models'
    face_recognition_key_str = f'{models_key_str}.face_recognition'

    # ëª¨ë¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
    models_dir_key_str = f'{face_recognition_key_str}.models_dir'
    # get_path ë‚´ë¶€ì—ì„œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë° ë¡œê¹…ì´ ë˜ë¯€ë¡œ, ë°˜í™˜ ê°’ì´ Noneì¸ì§€ ì—¬ë¶€ë§Œ ì²´í¬í•©ë‹ˆë‹¤.
    models_dir_str = cfg_obj.get_path(models_dir_key_str, ensure_exists=True) # ensure_exists=True ì „ë‹¬
    models_dir = Path(models_dir_str)
    if models_dir is None:
        # get_pathì—ì„œ ì´ë¯¸ ë¡œê¹…í–ˆìœ¼ë¯€ë¡œ ì¶”ê°€ ë¡œê¹…ì€ ìƒëµ ê°€ëŠ¥
        # logger.warning(f"dlib ëª¨ë¸ ë””ë ‰í† ë¦¬ '{models_dir_key_str}'ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return None
    logger.debug(f"ëª¨ë¸ì´ ìˆëŠ” ìœ„ì¹˜(models_dir): {models_dir}")

    # ì–¼êµ´ ì¸ì‹ ëª¨ë¸ íŒŒì¼ ì´ë¦„ ê°€ì ¸ì˜¤ê¸° ë° ê²½ë¡œ ìƒì„±
    face_rec_model_name_key = f'{face_recognition_key_str}.face_rec_model_name'
    face_rec_model_name = cfg_obj.get_value(face_rec_model_name_key) # get_valueì—ì„œ Path ê°ì²´ ë°˜í™˜ ê°€ì •
    if face_rec_model_name is None:
        logger.warning(f"dlib ì–¼êµ´ ì¸ì‹ ëª¨ë¸ íŒŒì¼ ì´ë¦„ ì„¤ì • ê°’ '{face_rec_model_name_key}'ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return None
    # get_valueì—ì„œ Path ê°ì²´ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ / ì—°ì‚°ì ì‚¬ìš© ê°€ëŠ¥
    logger.debug(f"ëª¨ë”œ ì´ë¦„ì€(face_rec_model_name): {face_rec_model_name}")

    # get_valueì—ì„œ Path ê°ì²´ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ / ì—°ì‚°ì ì‚¬ìš© ê°€ëŠ¥
    landmark_model_name_key = f'{face_recognition_key_str}.landmark_model_name' # ì˜ˆì‹œ í‚¤ ì´ë¦„
    landmark_model_name = cfg_obj.get_value(landmark_model_name_key) # get_valueì—ì„œ Path ê°ì²´ ë°˜í™˜ ê°€ì •
    if landmark_model_name is None:
        logger.warning(f"dlib ëœë“œë§ˆí¬ ëª¨ë¸ íŒŒì¼ ì´ë¦„ ì„¤ì • ê°’ '{landmark_model_name_key}'ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return None

    # dlib ëª¨ë¸ ë¡œë“œ ì‹œë„
    face_rec_model_path = models_dir / face_rec_model_name
    landmark_model_path = models_dir / landmark_model_name
    try:
        # ë¡œë“œëœ ëª¨ë¸ ê°ì²´ë¥¼ í•¨ìˆ˜ ë‚´ ë¡œì»¬ ë³€ìˆ˜ì— í• ë‹¹
        face_detector_dlib = dlib.get_frontal_face_detector()
        shape_predictor_obj = dlib.shape_predictor(str(landmark_model_path))
        face_recognizer_obj = dlib.face_recognition_model_v1(str(face_rec_model_path))

        logger.debug("dlib ì–¼êµ´ ì¸ì‹ ê´€ë ¨ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

        # ë¡œë“œëœ ëª¨ë¸ ê°ì²´ë“¤ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë¬¶ì–´ ë°˜í™˜
        loaded_models = {
            'face_detector': face_detector_dlib,
            'shape_predictor': shape_predictor_obj,
            'face_recognizer': face_recognizer_obj
        }
        return loaded_models

    except Exception as e:
        # dlib ëª¨ë¸ ë¡œë“œ ìì²´ì—ì„œ ì˜¤ë¥˜ ë°œìƒ
        logger.error(f"dlib ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None # ë¡œë“œ ì‹¤íŒ¨ ì‹œ None ë°˜í™˜
from typing import Callable

def get_all_face_data_from_json_batch(
    cfg: configger,
    json_file_path: Path,
    json_key_config: Dict[str, Any],
    process_func: Callable[[np.ndarray, Dict[str, Any]], None]
) -> int:
    """
    JSON íŒŒì¼ì—ì„œ ì–¼êµ´ ì„ë² ë”©ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ í•˜ë‚˜ì”© ì¶”ì¶œí•˜ë©°
    ì£¼ì–´ì§„ ì²˜ë¦¬ í•¨ìˆ˜(process_func)ë¥¼ í†µí•´ ì™¸ë¶€ ë°°ì¹˜ ì»¨íŠ¸ë¡¤ëŸ¬ì— ì „ë‹¬í•©ë‹ˆë‹¤.

    Args:
        cfg: ì„¤ì • ê°ì²´
        json_file_path: ëŒ€ìƒ JSON íŒŒì¼ ê²½ë¡œ
        json_key_config: JSON êµ¬ì¡° í‚¤ ë§µ
        process_func: (ì„ë² ë”©, ë©”íƒ€ë°ì´í„°) â†’ ì²˜ë¦¬ í•¨ìˆ˜ (ì˜ˆ: ë°°ì¹˜ ëˆ„ì ê¸°)

    Returns:
        ì²˜ë¦¬ëœ ì–¼êµ´ ìˆ˜
    """
    logger.info(f"[ë°°ì¹˜ìš©] JSON íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {json_file_path.name}")

    count = 0

    try:
        with open(json_file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        detected_objects = data.get(
            json_key_config.get("detected_objects_list_key", "detected_obj")
        )
        if not isinstance(detected_objects, list):
            return 0

        # í‚¤ ë§µ ê°€ì ¸ì˜¤ê¸°
        image_path = data.get(json_key_config.get("image_info_keys", {}).get("path", "image_path"))
        image_hash = data.get(json_key_config.get("image_info_keys", {}).get("hash", "image_hash"))

        for obj in detected_objects:
            faces = obj.get(
                json_key_config.get("object_keys", {}).get("face_crops_list_key", "detected_face_crop"), []
            )
            for face in faces:
                embedding_data = face.get(
                    json_key_config.get("face_keys", {}).get("embedding", "embedding")
                )
                if not embedding_data:
                    continue

                try:
                    embedding_np = np.array(embedding_data, dtype=np.float32)
                except Exception as e:
                    logger.warning(f"ì„ë² ë”© ë³€í™˜ ì‹¤íŒ¨: {e}")
                    continue

                metadata = {
                    "source_json_path": str(json_file_path),
                    "original_image_path": image_path,
                    "original_image_hash": image_hash,
                    "face_id": face.get("face_id"),
                    "face_bbox_in_obj": face.get("box"),
                    "embedding_score": face.get("score"),
                    "detected_face_bbox_xyxy": face.get("bbox_xyxy"),
                    "detected_face_confidence": face.get("confidence"),
                    "detected_face_label": face.get("label"),
                    "detected_object_class": obj.get("class_name"),
                    "detected_object_bbox_xyxy": obj.get("box_xyxy")
                }

                # â–¶ ì²˜ë¦¬ í•¨ìˆ˜ì— ì „ë‹¬ (ex. ë°°ì¹˜ ëˆ„ì ê¸°)
                process_func(embedding_np, metadata)
                count += 1

        return count

    except Exception as e:
        logger.error(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {json_file_path.name} - {e}", exc_info=True)
        return 0

def get_all_face_data_from_json_alone(
    cfg:configger, 
    json_file_path: Path
    ) -> Tuple[List[np.ndarray], List[Dict[str, Any]]]:
    """
    ì£¼ì–´ì§„ JSON íŒŒì¼ì—ì„œ ëª¨ë“  ì–¼êµ´ì˜ ì„ë² ë”©ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    í‚¤ ì´ë¦„ì€ json_key_config ë”•ì…”ë„ˆë¦¬ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    Args:
        json_file_path (Path): ì–¼êµ´ ì •ë³´ë¥¼ ì¶”ì¶œí•  JSON íŒŒì¼ì˜ ê²½ë¡œ.
        json_key_config (Dict[str, Any]): 
                config.yamlì˜ data_structure_keys ì„¹ì…˜ì—ì„œ ë¡œë“œí•œ ì„¤ì • ë”•ì…”ë„ˆë¦¬.
                YAML êµ¬ì¡°ì— ë”°ë¼ ì¤‘ì²©ëœ ë”•ì…”ë„ˆë¦¬ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    Returns:
        Tuple[List[np.ndarray], List[Dict[str, Any]]]:
            - ì¶”ì¶œëœ ëª¨ë“  ì–¼êµ´ ì„ë² ë”© ë¦¬ìŠ¤íŠ¸ (ê° ìš”ì†ŒëŠ” NumPy ë°°ì—´).
            - ì¶”ì¶œëœ ëª¨ë“  ì–¼êµ´ ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸.
            - ì˜¤ë¥˜ ë°œìƒ ë˜ëŠ” ë°ì´í„° ì—†ìŒ ì‹œ ([], []) ë°˜í™˜.
    """
    # 0. ì¼ì¤€ë¹„
    # 0.1. í†µê³„ ì •ë³´ë¥¼ ë‹´ì„ ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
    status = {k: {"value": v["value"], "msg": v["msg"]} for k, v in DEFAULT_STATUS_TEMPLATE.items()}

    # 0.1. ê²°ê³¼ë¬¼ì„ ì„ì‹œë¡œ ë‹´ì„ ë””ë ‰í† ë¦¬ ë§Œë“¤ê¸° ì´ˆê¸°í™”
    embeddings_in_file: List[np.ndarray] = []
    metadatas_in_file: List[Dict[str, Any]] = []

    # # --- configì—ì„œ JSON í‚¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸° ---
    # # json_key_configì˜ êµ¬ì¡°ì— ë§ì¶° ë‹¨ê³„ì ìœ¼ë¡œ ì ‘ê·¼í•©ë‹ˆë‹¤.

    # # ìµœìƒìœ„ 'detected_obj' ë¦¬ìŠ¤íŠ¸ì˜ í‚¤ ì´ë¦„
    # ì´ë¯¸ì§€ ì •ë³´ ê´€ë ¨ í‚¤ ì´ë¦„ë“¤ì„ ê°€ì ¸ì˜¤ê¸° ìœ„í•œ ì„¤ì • ê²½ë¡œ ë¬¸ìì—´
    json_keys_str           = 'json_keys'
    image_info_key_str      = f'{json_keys_str}.image_info_key'
    logger.debug(f"image_info_key_str: {image_info_key_str}")

    # ì„¤ì •ì—ì„œ ì‹¤ì œ í‚¤ ê°’ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    try:

        image_name_key_str      = f'{image_info_key_str}.name_key'
        image_name_key          = cfg.get_value(image_name_key_str)
        image_path_key_str      = f'{image_info_key_str}.path_key'
        image_path_key          = cfg.get_value(image_path_key_str)
        image_hash_key_str      = f'{image_info_key_str}.hash_key'
        image_hash_key          = cfg.get_value(image_hash_key_str)

        detected_obj_key_str    = f'{json_keys_str}.detected_obj_key'
        # object_name_keyëŠ” ì‹¤ì œ JSON íŒŒì¼ ë‚´ ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ë¦¬í‚¤ëŠ” í‚¤ì˜ ì´ë¦„ (ì˜ˆ: "detected_obj")
        object_list_key_name_str = f'{detected_obj_key_str}.object_name_key' # YAML ì„¤ì •ìƒ object_name_keyê°€ ê°ì²´ ë¦¬ìŠ¤íŠ¸ì˜ í‚¤ ì´ë¦„
        object_list_key_val    = cfg.get_value(object_list_key_name_str)
        logger.debug(f"object_list_key_val (ê°ì²´ ë¦¬ìŠ¤íŠ¸ í‚¤): {object_list_key_val}")

        object_info_key_str     = f'{detected_obj_key_str}.object_info_key'
        # ê°ì²´ ë‚´ í´ë˜ìŠ¤ ì´ë¦„ê³¼ ë°”ìš´ë”© ë°•ìŠ¤ í‚¤
        object_class_name_key_config_path = f'{object_info_key_str}.class_name_key'
        object_class_name_key_val = cfg.get_value(object_class_name_key_config_path)
        object_box_xyxy_key_config_path = f'{object_info_key_str}.box_xyxy_key'
        object_box_xyxy_key_val = cfg.get_value(object_box_xyxy_key_config_path)

        detected_face_key_str   = f'{object_info_key_str}.detected_face_key'
        # face_name_keyëŠ” ê°ì²´ ë‚´ì˜ ì–¼êµ´ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ë¦¬í‚¤ëŠ” í‚¤ì˜ ì´ë¦„ (ì˜ˆ: "detected_face")
        face_name_key_str       = f'{detected_face_key_str}.face_name_key'
        face_list_in_obj_key_val = cfg.get_value(face_name_key_str) # ê°ì²´ ë‚´ ì–¼êµ´ ë¦¬ìŠ¤íŠ¸ í‚¤
        logger.debug(f"face_list_in_obj_key_val (ê°ì²´ ë‚´ ì–¼êµ´ ë¦¬ìŠ¤íŠ¸ í‚¤): {face_list_in_obj_key_val}")

        detected_face_key_str   = f'json_keys.detected_obj_key.face_info_key'
        face_key_list = cfg.get_key_list(detected_face_key_str)

        face_info_key_str       = f'{detected_face_key_str}.face_info_key'
        face_bbox_xyxy_key_str  = f'{face_info_key_str}.bbox_xyxy_key'
        face_bbox_xyxy_key_val  = cfg.get_value(face_bbox_xyxy_key_str)
        face_confidence_key_str = f'{face_info_key_str}.confidence_key'
        face_confidence_key_val = cfg.get_value(face_confidence_key_str)
        face_label_key_str      = f'{face_info_key_str}.label_key'
        face_label_key_val      = cfg.get_value(face_label_key_str)
        face_embedding_key_str  = f'{face_info_key_str}.embedding_key'
        face_embedding_key_val  = cfg.get_value(face_embedding_key_str)
        face_face_id_key_str    = f'{face_info_key_str}.face_id_key'
        face_face_id_key_val    = cfg.get_value(face_face_id_key_str)
        face_box_key_str        = f'{face_info_key_str}.box_key'
        face_box_key_val        = cfg.get_value(face_box_key_str)
        face_score_key_str      = f'{face_info_key_str}.score_key'
        logger.debug(f"face_score_key_str: {face_score_key_str}")
        face_score_key_val      = cfg.get_value(face_score_key_str)

    except Exception as e:
        logger.error(f"ì„¤ì • íŒŒì¼ì—ì„œ JSON í‚¤ ê°’ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (íŒŒì¼: {json_file_path.name}): {e}", exc_info=True)
        return [], []
    
    try:
        with open(json_file_path, 'r', encoding='utf-8') as f:
            json_data = json.load(f)

        # JSON íŒŒì¼ì—ì„œ ìµœìƒìœ„ ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        # object_list_key_valì€ "detected_obj"ì™€ ê°™ì€ ë¬¸ìì—´ í‚¤ ì´ë¦„ì…ë‹ˆë‹¤.
        logger.debug(f"object_list_key_val: '{object_list_key_val}'")
        actual_objects_list = json_data.get(object_list_key_val)

        if not isinstance(actual_objects_list, list):
            logger.warning(f"JSON íŒŒì¼ '{json_file_path.name}'ì— '{object_list_key_val}' í‚¤ë¡œ ì‹ë³„ë˜ëŠ” ë¦¬ìŠ¤íŠ¸ê°€ ì—†ê±°ë‚˜ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return [], []

        # ì´ë¯¸ì§€ ë ˆë²¨ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        original_image_path = json_data.get(image_path_key) # image_path_keyëŠ” ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¨ ê°’
        original_image_hash = json_data.get(image_hash_key) # image_hash_keyëŠ” ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¨ ê°’
        for obj_entry in actual_objects_list: # ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœíšŒí•©ë‹ˆë‹¤.
            if not isinstance(obj_entry, dict): continue # ê° ê°ì²´ëŠ” ë”•ì…”ë„ˆë¦¬ì—¬ì•¼ í•©ë‹ˆë‹¤.

            # í˜„ì¬ ê°ì²´ì—ì„œ ì–¼êµ´ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. face_list_in_obj_key_valì€ "detected_face"ì™€ ê°™ì€ ë¬¸ìì—´ í‚¤ ì´ë¦„ì…ë‹ˆë‹¤.
            faces_in_object_list = obj_entry.get(face_list_in_obj_key_val)
            if not isinstance(faces_in_object_list, list):
                continue

            for face_entry in faces_in_object_list: # ê°ì²´ ë‚´ ì–¼êµ´ ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœíšŒí•©ë‹ˆë‹¤.
                if not isinstance(face_entry, dict): continue # ê° ì–¼êµ´ í•­ëª©ì€ ë”•ì…”ë„ˆë¦¬ì—¬ì•¼ í•©ë‹ˆë‹¤.

                embedding_data = face_entry.get(face_embedding_key_val) # ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¨ í‚¤ ì‚¬ìš©
                if embedding_data is None:
                    face_id_info = face_entry.get(face_face_id_key_val, 'N/A')
                    logger.debug(f"JSON íŒŒì¼ '{json_file_path.name}'ì˜ face_id '{face_id_info}'ì— '{face_embedding_key_val}' ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆ<0xEB><0><0x8E>ë‹ˆë‹¤.")
                    continue
                try:
                    embedding_np = np.array(embedding_data, dtype=np.float32)
                except Exception as e_np:
                    face_id_info = face_entry.get(face_face_id_key_val, 'N/A')
                    logger.warning(f"JSON íŒŒì¼ '{json_file_path.name}'ì˜ face_id '{face_id_info}' ì„ë² ë”© ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e_np}. ê±´ë„ˆ<0xEB><0><0x8E>ë‹ˆë‹¤.")
                    continue

                metadata = {
                    "source_json_path": str(json_file_path),
                    "original_image_path": original_image_path,
                    "original_image_hash": original_image_hash,
                    "face_id": face_entry.get(face_face_id_key_val),
                    "face_bbox_in_obj": face_entry.get(face_box_key_val),
                    "embedding_score": face_entry.get(face_score_key_val),
                    "detected_face_bbox_xyxy": face_entry.get(face_bbox_xyxy_key_val),
                    "detected_face_confidence": face_entry.get(face_confidence_key_val),
                    "detected_face_label": face_entry.get(face_label_key_val),
                    "detected_object_class": obj_entry.get(object_class_name_key_val),
                    "detected_object_bbox_xyxy": obj_entry.get(object_box_xyxy_key_val)
                }
                embeddings_in_file.append(embedding_np)
                metadatas_in_file.append(metadata)

        return embeddings_in_file, metadatas_in_file

    except FileNotFoundError:
        logger.error(f"JSON íŒŒì¼ ì°¾ê¸° ì˜¤ë¥˜: {json_file_path}", exc_info=True)
        return [], []
    except json.JSONDecodeError:
        logger.error(f"JSON íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜: {json_file_path}", exc_info=True)
        return [], []
    except Exception as e:
        logger.error(f"JSON íŒŒì¼ '{json_file_path.name}' ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", exc_info=True)
        return [], []

#def add_embeddings_batch(embeddings: List[np.ndarray], metadatas: List[Dict[str, Any]], cfg_obj):
def add_embedding_to_index(embedding: np.ndarray, metadata: Dict[str, Any], cfg_obj):
    """
    ë‹¨ì¼ ì–¼êµ´ ì„ë² ë”©ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ ë°›ì•„ FAISS ì¸ë±ìŠ¤ì— ì¶”ê°€í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
    ì €ì‚¬ì–‘ í™˜ê²½ì— ì í•©í•œ ë°©ì‹ (IndexFlatL2 + ë§ë¶™ì´ê¸° ì €ì¥)ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤.
    """
    status = {k: {"value": v["value"], "msg": v["msg"]} for k, v in DEFAULT_STATUS_TEMPLATE.items()}

    try:
        embedding = embedding.astype('float32').reshape(1, -1)
        embedding_dim = embedding.shape[1]

        # ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
        index_file_path_str = cfg_obj.get_value('indexing.index_file_path')
        metadata_file_path_str = cfg_obj.get_value('indexing.metadata_path')

        if not index_file_path_str or not metadata_file_path_str:
            logger.critical("í•„ìˆ˜ ì„¤ì •(index_file_path ë˜ëŠ” metadata_path)ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return

        index_file_path = Path(index_file_path_str)
        metadata_file_path = Path(metadata_file_path_str)

        # ë””ë ‰í† ë¦¬ ìƒì„±
        index_file_path.parent.mkdir(parents=True, exist_ok=True)
        metadata_file_path.parent.mkdir(parents=True, exist_ok=True)

        # ì¸ë±ìŠ¤ íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ë¶ˆëŸ¬ì˜¤ê³ , ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        if index_file_path.exists():
            index = faiss.read_index(str(index_file_path))
            if index.d != embedding_dim:
                status["error_embeddings_deff_drainage"]["value"] += 1
                logger.warning(f"ì„ë² ë”© ì°¨ì› ë¶ˆì¼ì¹˜: ê¸°ì¡´ ì¸ë±ìŠ¤({index.d}) vs ì…ë ¥({embedding_dim})")
                return
        else:
            index = faiss.IndexFlatL2(embedding_dim)
            logger.info(f"ìƒˆë¡œìš´ IndexFlatL2 ìƒì„± (ì°¨ì›: {embedding_dim})")

        # ì¸ë±ìŠ¤ì— ì¶”ê°€
        index.add(embedding)
        faiss.write_index(index, str(index_file_path))
        logger.info(f"ì¸ë±ìŠ¤ì— 1ê°œ ë²¡í„° ì¶”ê°€. í˜„ì¬ ì´ ë²¡í„° ìˆ˜: {index.ntotal}")

        # ë©”íƒ€ë°ì´í„° ì €ì¥ (append)
        with open(metadata_file_path, 'a', encoding='utf-8') as f:
            f.write(json.dumps(metadata, ensure_ascii=False) + '\n')
        logger.info("ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ.")

    except Exception as e:
        logger.critical(f"ì¸ë±ìŠ¤ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)

def build_and_save_index_alone(
        embeddings: List[np.ndarray], 
        metadatas: List[Dict[str, Any]], 
        cfg_obj: configger
    ):
    """
    ìˆ˜ì§‘ëœ ì–¼êµ´ íŠ¹ì§• ë²¡í„°(embeddings)ì™€ í•´ë‹¹ ë©”íƒ€ë°ì´í„°(metadatas)ë¥¼ ì‚¬ìš©í•˜ì—¬
    FAISS ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•˜ê³ , ì¸ë±ìŠ¤ íŒŒì¼ê³¼ ë©”íƒ€ë°ì´í„° íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤.
    ì¸ë±ì‹± ê´€ë ¨ ì„¤ì •(íŒŒì¼ ê²½ë¡œ, FAISS ì¸ë±ìŠ¤ íƒ€ì…, ì„ë² ë”© ì°¨ì› ë“±)ì€
    ì„¤ì • ê°ì²´(cfg_obj)ì˜ 'indexing' ì„¹ì…˜ì—ì„œ ì½ì–´ì˜µë‹ˆë‹¤.
    Args:
        embeddings (List[np.ndarray]): ì¸ë±ì‹±í•  ì–¼êµ´ íŠ¹ì§• ë²¡í„°ë“¤ì˜ ë¦¬ìŠ¤íŠ¸. ê° ìš”ì†ŒëŠ” NumPy ë°°ì—´.
        metadatas (List[Dict[str, Any]]): ê° íŠ¹ì§• ë²¡í„°ì— í•´ë‹¹í•˜ëŠ” ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬ë“¤ì˜ ë¦¬ìŠ¤íŠ¸.
                                         ë¦¬ìŠ¤íŠ¸ ìˆœì„œëŠ” embeddings ë¦¬ìŠ¤íŠ¸ì™€ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
        cfg_obj (configger): ì„¤ì • íŒŒì¼ ë‚´ìš©ì„ ë‹´ê³  ìˆëŠ” configger ê°ì²´.
    """
    status = {k: {"value": v["value"], "msg": v["msg"]} for k, v in DEFAULT_STATUS_TEMPLATE.items()}

    if not embeddings:
        # ì¸ë±ì‹±í•  ì„ë² ë”© ë°ì´í„°ê°€ ì—†ìœ¼ë©´, ì •ë³´ ë¡œê¹… í›„ í•¨ìˆ˜ ì¢…ë£Œ
        logger.info("ì¸ë±ì‹±í•  ì–¼êµ´ íŠ¹ì§• ë²¡í„°ê°€ ì—†ìŠµë‹ˆë‹¤. FAISS ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        status["error_embedding_empty_target"]["value"] += 1
        return

    try:
        # FAISSëŠ” float32 íƒ€ì…ì˜ NumPy ë°°ì—´ì„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        embeddings_array = np.array(embeddings).astype('float32')
        if embeddings_array.ndim == 1: # ë‹¨ì¼ ì„ë² ë”©ë§Œ ìˆëŠ” ê²½ìš° 2Dë¡œ ë³€í™˜
            if embeddings_array.size > 0:
                embeddings_array = embeddings_array.reshape(1, -1)
            else: # ë¹ˆ ì„ë² ë”©ì¸ ê²½ìš°
                logger.info("ë¹ˆ ì„ë² ë”© ë°°ì—´ì…ë‹ˆë‹¤. FAISS ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                status["error_embeddings_array"]["value"] += 1
                return

        embedding_dim = embeddings_array.shape[1]  # íŠ¹ì§• ë²¡í„°ì˜ ì°¨ì› (ì˜ˆ: dlibì€ 128ì°¨ì›)

        logger.info(f"ì´ {len(embeddings_array)}ê°œì˜ ì–¼êµ´ íŠ¹ì§• ë²¡í„°({embedding_dim} ì°¨ì›) ìˆ˜ì§‘ ì™„ë£Œ. FAISS ì¸ë±ìŠ¤ êµ¬ì¶• ì‹œì‘.")

        # --- FAISS ì¸ë±ìŠ¤ êµ¬ì¶• ì„¤ì • (YAML íŒŒì¼ì˜ 'indexing' ì„¹ì…˜ì—ì„œ ë¡œë“œ) ---
        index_file_path_str = cfg_obj.get_value('indexing.index_file_path')
        metadata_file_path_str = cfg_obj.get_value('indexing.metadata_path')
        faiss_index_type = cfg_obj.get_value('indexing.faiss_index_type', 'IndexFlatL2') # ê¸°ë³¸ê°’: IndexFlatL2
        
        # configured_embedding_dimì€ JSONì—ì„œ ì§ì ‘ ì½ì–´ì˜¨ ì„ë² ë”©ì˜ ì°¨ì›ì„ ì‚¬ìš©í•˜ë¯€ë¡œ,
        # YAML ì„¤ì •ì˜ embedding_dimì€ ì°¸ê³ ìš© ë˜ëŠ” ê²€ì¦ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©í•˜ê±°ë‚˜ ì œê±° ê°€ëŠ¥.
        # ì—¬ê¸°ì„œëŠ” YAMLì˜ embedding_dimê³¼ ì‹¤ì œ ë°ì´í„°ì˜ ì°¨ì›ì„ ë¹„êµí•˜ëŠ” ë¡œì§ì„ ìœ ì§€í•©ë‹ˆë‹¤.
        configured_embedding_dim_yaml = cfg_obj.get_value('indexing.embedding_dim')
        if configured_embedding_dim_yaml is not None:
            configured_embedding_dim_yaml = int(configured_embedding_dim_yaml)
            if configured_embedding_dim_yaml != embedding_dim:
                status["error_embeddings_deff_config"]["value"] += 1
                logger.warning(
                    f"YAMLì— ì„¤ì •ëœ embedding_dim ({configured_embedding_dim_yaml})ê³¼ "
                    f"ì‹¤ì œ ë°ì´í„°ì˜ íŠ¹ì§• ë²¡í„° ì°¨ì› ({embedding_dim})ì´ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
                    f"ì‹¤ì œ ë°ì´í„° ì°¨ì›ì¸ {embedding_dim}ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
                )
        else:
            status["error_embeddings_deff_config"]["value"] += 1
            logger.info(f"YAMLì— 'indexing.embedding_dim'ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‹¤ì œ ë°ì´í„° ì°¨ì› {embedding_dim}ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")


        # í•„ìˆ˜ ì„¤ì •ê°’ë“¤ì´ ì œëŒ€ë¡œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
        if not index_file_path_str or not metadata_file_path_str:
            status["error_embeddings_deff_config"]["value"] += 1
            logger.critical("YAML ì„¤ì • íŒŒì¼ì˜ 'indexing' ì„¹ì…˜ ë˜ëŠ” í•„ìˆ˜ í‚¤(index_file_path, metadata_path)ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return

        index_file_path = Path(index_file_path_str)  # ì¸ë±ìŠ¤ íŒŒì¼ ì €ì¥ ê²½ë¡œ
        metadata_file_path = Path(metadata_file_path_str)  # ë©”íƒ€ë°ì´í„° íŒŒì¼ ì €ì¥ ê²½ë¡œ

        index = None  # FAISS ì¸ë±ìŠ¤ ê°ì²´ ì´ˆê¸°í™”

        # --- FAISS ì¸ë±ìŠ¤ íƒ€ì…ì— ë”°ë¥¸ ì¸ë±ìŠ¤ ìƒì„± ---
        logger.info(f"FAISS ì¸ë±ìŠ¤ íƒ€ì…: '{faiss_index_type}' (ì„ë² ë”© ì°¨ì›: {embedding_dim})")

        if faiss_index_type == 'IndexFlatL2':
            index = faiss.IndexFlatL2(embedding_dim)
        elif faiss_index_type == 'IndexFlatIP':
            index = faiss.IndexFlatIP(embedding_dim)
        elif faiss_index_type == 'IndexIVFFlat':
            nlist = int(cfg_obj.get_value('indexing.nlist', 100)) 
            quantizer = faiss.IndexFlatL2(embedding_dim)
            index = faiss.IndexIVFFlat(quantizer, embedding_dim, nlist, faiss.METRIC_L2)
            logger.info(f"  - IndexIVFFlat íŒŒë¼ë¯¸í„°: nlist={nlist}")
            if embeddings_array.shape[0] < nlist:
                status["error_embeddings_deff_spec"]["value"] += 1
                logger.warning(f"  ê²½ê³ : í•™ìŠµ ë°ì´í„° ìˆ˜({embeddings_array.shape[0]})ê°€ nlist({nlist})ë³´ë‹¤ ì ìŠµë‹ˆë‹¤. IVFFlat í•™ìŠµì— ì˜í–¥ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            if embeddings_array.shape[0] > 0: # í•™ìŠµ ë°ì´í„°ê°€ ìˆì–´ì•¼ í•™ìŠµ ê°€ëŠ¥
                logger.info("  IndexIVFFlat í•™ìŠµ ì‹œì‘...")
                index.train(embeddings_array)
                logger.info("  IndexIVFFlat í•™ìŠµ ì™„ë£Œ.")
            else:
                status["error_embeddings_none_learn"]["value"] += 1
                logger.warning("  í•™ìŠµ ë°ì´í„°ê°€ ì—†ì–´ IndexIVFFlat í•™ìŠµì„ ê±´ë„ˆ<0xEB><0><0x8E>ë‹ˆë‹¤.")
        elif faiss_index_type == 'IndexIVFPQ':
            nlist = int(cfg_obj.get_value('indexing.nlist', 100))
            M = int(cfg_obj.get_value('indexing.M', 8)) 
            nbits = int(cfg_obj.get_value('indexing.nbits', 8))
            logger.info(f"  - IndexIVFPQ íŒŒë¼ë¯¸í„°: nlist={nlist}, M={M}, nbits={nbits}")

            if embedding_dim % M != 0:
                status["error_embeddings_none_learn"]["value"] += 1
                logger.warning(f"  ê²½ê³ : IndexIVFPQ ì‚¬ìš© ì‹œ embedding_dim({embedding_dim})ì´ M({M})ì˜ ë°°ìˆ˜ê°€ ì•„ë‹™ë‹ˆë‹¤. ì„±ëŠ¥ ì €í•˜ ë˜ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            quantizer = faiss.IndexFlatL2(embedding_dim)
            index = faiss.IndexIVFPQ(quantizer, embedding_dim, nlist, M, nbits)
            if embeddings_array.shape[0] < nlist: 
                status["error_embeddings_deff_drainage"]["value"] += 1
                logger.warning(f"  ê²½ê³ : í•™ìŠµ ë°ì´í„° ìˆ˜({embeddings_array.shape[0]})ê°€ nlist({nlist})ë³´ë‹¤ ì ìŠµë‹ˆë‹¤. IVFPQ í•™ìŠµì— ì˜í–¥ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            if embeddings_array.shape[0] > 0: # í•™ìŠµ ë°ì´í„°ê°€ ìˆì–´ì•¼ í•™ìŠµ ê°€ëŠ¥
                logger.info("  IndexIVFPQ í•™ìŠµ ì‹œì‘...")
                index.train(embeddings_array)
                logger.info("  IndexIVFPQ í•™ìŠµ ì™„ë£Œ.")
            else:
                status["error_embeddings_none_learn"]["value"] += 1
                logger.warning("  í•™ìŠµ ë°ì´í„°ê°€ ì—†ì–´ IndexIVFPQ í•™ìŠµì„ ê±´ë„ˆ<0xEB><0><0x8E>ë‹ˆë‹¤.")
        else:
            status["error_embeddings_none_serport_type"]["value"] += 1
            logger.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” FAISS ì¸ë±ìŠ¤ íƒ€ì…ì…ë‹ˆë‹¤: '{faiss_index_type}'.")
            logger.error("ì§€ì› íƒ€ì…: IndexFlatL2, IndexFlatIP, IndexIVFFlat, IndexIVFPQ")
            return

        if index is None:
            status["error_embeddings_objebt_gen"]["value"] += 1
            logger.critical("FAISS ì¸ë±ìŠ¤ ê°ì²´ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return
        
        if embeddings_array.shape[0] > 0: # ì¶”ê°€í•  ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ add ìˆ˜í–‰
            index.add(embeddings_array)
            logger.info(f"FAISS ì¸ë±ìŠ¤ì— ì´ {index.ntotal}ê°œì˜ ë²¡í„° ì¶”ê°€ ì™„ë£Œ.")
        else:
            status["error_embeddings_none_learn"]["value"] += 1
            logger.info("ì¶”ê°€í•  ì„ë² ë”© ë°ì´í„°ê°€ ì—†ì–´ FAISS ì¸ë±ìŠ¤ì— ë²¡í„°ë¥¼ ì¶”ê°€í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


        # --- ì¸ë±ìŠ¤ íŒŒì¼ ë° ë©”íƒ€ë°ì´í„° íŒŒì¼ ì €ì¥ ---
        index_file_path.parent.mkdir(parents=True, exist_ok=True)
        metadata_file_path.parent.mkdir(parents=True, exist_ok=True)

        faiss.write_index(index, str(index_file_path))
        logger.info(f"FAISS ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ: {index_file_path}")

        with open(metadata_file_path, 'w', encoding='utf-8') as f:
            for meta_item in metadatas:
                f.write(json.dumps(meta_item, ensure_ascii=False) + '\n')
        logger.info(f"ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {metadata_file_path}")

    except KeyError as e:
        logger.critical(f"FAISS ì¸ë±ìŠ¤ êµ¬ì¶• ì„¤ì • ì¤‘ í•„ìˆ˜ í‚¤ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {e}")
        logger.critical("YAML ì„¤ì • íŒŒì¼ì˜ 'indexing' ì„¹ì…˜ì„ í™•ì¸í•´ì£¼ì„¸ìš” (ì˜ˆ: index_file_path, metadata_path, faiss_index_type ë“±).")
    except Exception as e:
        logger.critical(f"FAISS ì¸ë±ìŠ¤ êµ¬ì¶• ë° ì €ì¥ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)

def run_main(cfg: configger):
    # 0. ì¼ ì¤€ë¹„
    # 0.1. í†µê³„ ì •ë³´ë¥¼ ë‹´ì„ ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
    status = {k: {"value": v["value"], "msg": v["msg"]} for k, v in DEFAULT_STATUS_TEMPLATE.items()}
    BATCH_SIZE = int(cfg.get_value("indexing.batch_size", 4))  # ì„¤ì •ê°’ ë˜ëŠ” ê¸°ë³¸ê°’

    # 0.2. dlib ëª¨ë¸ ë¡œë“œëŠ” ì„ íƒ ì‚¬í•­ì´ ë˜ì—ˆìœ¼ë¯€ë¡œ, ì‹¤íŒ¨í•´ë„ ì¹˜ëª…ì ì´ì§€ ì•ŠìŒ
    loaded_dlib_models = load_dlib_models(cfg)

    if loaded_dlib_models is None:
        logger.warning("dlib ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨")
        return None

    try:
        detector = loaded_dlib_models['face_detector']
        predictor = loaded_dlib_models['shape_predictor']
        recognizer = loaded_dlib_models['face_recognizer']
    except KeyError as e:
        logger.critical(f"dlib ëª¨ë¸ ë¡œë”© ì¤‘ í•„ìˆ˜ í‚¤ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {e}")
        logger.critical("dlib ëª¨ë¸ ë¡œë“œ, í•„ìš”í•œ í‚¤(face_detector, shape_predictor, face_recognizer)ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return None
    except Exception as e:
        logger.critical(f"dlib ëª¨ë¸ ë¡œë”© ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None
    logger.info("dlib ì–¼êµ´ ì¸ì‹ ê´€ë ¨ ëª¨ë¸ ë¡œë“œ ì™„ë£Œì™€ ê° ê°’ì„ ê°€ì €ì˜´.")

    # 0.3. ì…ë ¥ ë””ë ‰í† ë¦¬ ë° JSON í‚¤ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    dataset_base_key_str = "project.paths.datasets"
    input_dir_key = f"{dataset_base_key_str}.raw_jsons_dir"
    input_dir_str = cfg.get_value(input_dir_key)
    input_dir = Path(input_dir_str).expanduser().resolve()

    # 1. JSON íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    """
    íŒŒì¼ ê°œìˆ˜ê°€ ì¼ë°˜ì ì¸ ìˆ˜ì¤€ì„ ë„˜ì–´ ë§¤ìš° ë§ë‹¤ê³  íŒë‹¨ë˜ì‹ ë‹¤ë©´, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìµœì†Œí™”í•˜ë©´ì„œ 
    .json íŒŒì¼ ê²½ë¡œë¥¼ ì²˜ë¦¬í•˜ëŠ” ë‹¤ë¥¸ ë°©ë²•ì„ ê³ ë ¤í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
    ë¦¬ìŠ¤íŠ¸ì— ëª¨ë“  ê²½ë¡œë¥¼ í•œ ë²ˆì— ì €ì¥í•˜ëŠ” ëŒ€ì‹ , íŒŒì¼ ê²½ë¡œë¥¼ 'ìƒì„±ê¸°(generator)' í˜•íƒœë¡œ ë‹¤ë£¨ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.
    ê°€ì¥ ì¢‹ì€ ë°©ë²•ì€ globì˜ ê²°ê³¼ ìì²´ë¥¼ ë°”ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. 
    glob ë©”ì†Œë“œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ì´í„°ë ˆì´í„°(iterator)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. 
    ì´ ì´í„°ë ˆì´í„°ëŠ” ëª¨ë“  ê²½ë¡œë¥¼ í•œ ë²ˆì— ë©”ëª¨ë¦¬ì— ë¡œë“œí•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, 
    í•„ìš”í•  ë•Œë§ˆë‹¤ í•˜ë‚˜ì”© ê²½ë¡œë¥¼ ìƒì„±í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë§¤ìš° íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬ë©ë‹ˆë‹¤.
    ì›ë˜ ì½”ë“œì—ì„œ ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ [...]ì„ ì‚¬ìš©í–ˆê¸° ë•Œë¬¸ì— ê²°ê³¼ê°€ ë¦¬ìŠ¤íŠ¸ë¡œ ì¦‰ì‹œ ë©”ëª¨ë¦¬ì— ì €ì¥ëœ ê²ƒì…ë‹ˆë‹¤. 
    ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  glob ê²°ê³¼ ì´í„°ë ˆì´í„°ë¥¼ ì§ì ‘ ìˆœíšŒí•˜ë©´ ë©”ëª¨ë¦¬ ë¶€ë‹´ì„ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    # json_files = [p for p in input_dir.glob("**/*.json") if p.is_file()]
    # total_input_found = len(json_files)    """

    # 1.1. JSON íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ë° ì´ ê°œìˆ˜ ì„¸ê¸° (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
    logger.info(f"'{input_dir}' ë””ë ‰í† ë¦¬ì—ì„œ JSON íŒŒì¼ íƒìƒ‰ ì‹œì‘...")

    # glob ê²°ê³¼ ì´í„°ë ˆì´í„°ë¥¼ ìƒì„± (ê°œìˆ˜ ì„¸ê¸°ìš©)
    # ì´ ì´í„°ë ˆì´í„°ëŠ” ì•„ë˜ sum() í•¨ìˆ˜ì— ì˜í•´ ì†Œëª¨ë©ë‹ˆë‹¤.
    json_file_iterator_for_counting = input_dir.glob("**/*.json")

    # is_file() í•„í„°ë§ì„ ì ìš©í•˜ë©´ì„œ ê°œìˆ˜ ì„¸ê¸°
    # sum(1 for ...) êµ¬ë¬¸ì€ ì´í„°ë ˆì´í„°ë¥¼ ìˆœíšŒí•˜ë©° ê° ìš”ì†Œì— ëŒ€í•´ 1ì„ ë”í•˜ì—¬ ê°œìˆ˜ë¥¼ ì…‰ë‹ˆë‹¤.
    # ì´ ê³¼ì •ì—ì„œ ì „ì²´ ê²½ë¡œë¥¼ ë©”ëª¨ë¦¬ì— ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    total_input_found = sum(1 for p in json_file_iterator_for_counting if p.is_file())

    if total_input_found == 0:
        logger.warning(f"'{input_dir}' ë””ë ‰í† ë¦¬ì—ì„œ ì¸ë±ì‹±í•  JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        logger.info("âœ… ìµœì¢… í†µê³„:")
        logger.info(f"   - íƒìƒ‰ëœ JSON íŒŒì¼ ì´ ê°œìˆ˜: {total_input_found}")
        logger.info(f"   - ì¸ë±ì‹±ëœ ì´ ì–¼êµ´ ê°œìˆ˜: 0")
        logger.info(f"{Path(__file__).name} ì •ìƒ ì¢…ë£Œ (ì²˜ë¦¬í•  íŒŒì¼ ì—†ìŒ).")
        sys.exit(0)
    status["total_input_file"]["value"] = total_input_found

    logger.info(f'âœ… ì¸ë±ì‹±í•  JSON íŒŒì¼ {status["total_input_file"]["value"]}ê°œ ë°œê²¬.')

    digit_width = calc_digit_number(total_input_found)
    # 1.2. ëª¨ë“  íŒŒì¼ì—ì„œ ì–¼êµ´ ì •ë³´ ëˆ„ì  (ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ íŒŒì¼ ìˆœíšŒ)
    # glob ê²°ê³¼ë¥¼ ë‹¤ì‹œ ìƒì„± (ì‹¤ì œ ì²˜ë¦¬ìš©)
    # ê°œìˆ˜ë¥¼ ì„¸ëŠë¼ ì²« ë²ˆì§¸ ì´í„°ë ˆì´í„°ê°€ ì†Œëª¨ë˜ì—ˆìœ¼ë¯€ë¡œ, ì‹¤ì œ ì²˜ë¦¬ë¥¼ ìœ„í•´ì„œëŠ” ìƒˆë¡œ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.
    json_file_iterator_for_processing = input_dir.glob("**/*.json")

    all_embeddings: List[np.ndarray] = [] # ëª¨ë“  íŒŒì¼ì˜ ì„ë² ë”©ì„ ëˆ„ì í•  ë¦¬ìŠ¤íŠ¸
    all_metadatas: List[Dict[str, Any]] = [] # ëª¨ë“  íŒŒì¼ì˜ ë©”íƒ€ë°ì´í„°ë¥¼ ëˆ„ì í•  ë¦¬ìŠ¤íŠ¸
    total_faces_processed = 0 # ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ ì´ ì–¼êµ´ ê°œìˆ˜
    batch_index = 0  # ë°°ì¹˜ ì¹´ìš´í„°
    # total_faces_failed ë³€ìˆ˜ëŠ” í•„ìš”ì— ë”°ë¼ ì¶”ê°€

    logger.info("JSON íŒŒì¼ ë‚´ ì–¼êµ´ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘...")
    # enumerateë¥¼ ì‚¬ìš©í•˜ì—¬ ì§„í–‰ ìƒí™©ì„ í‘œì‹œí•˜ê¸° ìœ„í•´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ëŒ€ì‹ ,
    # total_input_found í™œìš©í•˜ì—¬ ìˆ˜ë™ìœ¼ë¡œ ì¹´ìš´íŠ¸í•˜ë©° ì§„í–‰ ìƒí™©ì„ í‘œì‹œí•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
    for json_file_path in json_file_iterator_for_processing: # ì´í„°ë ˆì´í„°ë¥¼ ìˆœíšŒ
        if not json_file_path.is_file():
            status["error_input_file_read"]["value"] += 1
            continue

        status["req_process_count"]["value"] += 1
        logger.debug(f"[{status["req_process_count"]["value"]:>{digit_width}}/{status["total_input_file"]["value"]}] JSON íŒŒì¼ ì²˜ë¦¬ ì¤‘: {json_file_path.name}")

        # 2. í˜„ì¬ íŒŒì¼(json_file_path)ì—ì„œ ì–¼êµ´ì˜ ì„ë² ë”©ê³¼ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì™€ì„œ indexing
        # json_key_config_dataë¥¼ ì „ë‹¬í•˜ë„ë¡ ìˆ˜ì •
        embeddings_from_file, metadatas_from_file = get_all_face_data_from_json_alone(
            cfg, 
            json_file_path
            )

        if embeddings_from_file: # íŒŒì¼ì—ì„œ ìœ íš¨í•œ ì„ë² ë”©ì´ ì¶”ì¶œëœ ê²½ìš°
            all_embeddings.extend(embeddings_from_file) # ëˆ„ì  ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            all_metadatas.extend(metadatas_from_file) # ëˆ„ì  ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            total_faces_processed += len(embeddings_from_file) # ì´ ì–¼êµ´ ê°œìˆ˜ ëˆ„ì 
            logger.info(f"  '{json_file_path.name}' íŒŒì¼ì—ì„œ ì–¼êµ´ {len(embeddings_from_file)}ê°œ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ. (ëˆ„ì  {total_faces_processed}ê°œ)")

            if len(all_embeddings) >= BATCH_SIZE:
                batch_index += 1
                logger.info(f"ğŸ”„ ë°°ì¹˜ {batch_index}: {len(all_embeddings)}ê°œ ì–¼êµ´ ì¸ë±ì‹± ì¤‘...")

                build_and_save_index_alone(all_embeddings, all_metadatas, cfg) # build_and_save_index_alone í˜¸ì¶œ

                # ëˆ„ì  ë°ì´í„° ì´ˆê¸°í™”
                all_embeddings.clear()
                all_metadatas.clear()
        else:
            # íŒŒì¼ ë‚´ì— ìœ íš¨í•œ ì–¼êµ´ ì •ë³´ê°€ ì—†ê±°ë‚˜ ì˜¤ë¥˜ ë°œìƒ ì‹œ
            status["error_embedding"]["value"] += 1
            logger.warning(f"  '{json_file_path.name}' íŒŒì¼ì—ì„œ ìœ íš¨í•œ ì–¼êµ´ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            # ì‹¤íŒ¨ ì¹´ìš´íŠ¸ ë¡œì§ì€ í•„ìš”ì— ë”°ë¼ ì¶”ê°€

        if status["req_process_count"]["value"] > 2:
            break
    # ğŸ”š ë‚¨ì€ ë°ì´í„°ê°€ ìˆì„ ê²½ìš° ë§ˆì§€ë§‰ ë°°ì¹˜ ì²˜ë¦¬
    if all_embeddings:
        batch_index += 1
        logger.info(f"ğŸ”„ ë§ˆì§€ë§‰ ë°°ì¹˜ {batch_index}: {len(all_embeddings)}ê°œ ì–¼êµ´ ì¸ë±ì‹± ì¤‘...")
        build_and_save_index_alone(all_embeddings, all_metadatas, cfg) # build_and_save_index_alone í˜¸ì¶œ

    # 9. ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ ë˜ëŠ” ì¤‘ë‹¨ í›„ ìì› í•´ì œ
    # 9-1. í†µê³„ ê²°ê³¼ ì¶œë ¥ ---
    # ê°€ì¥ ê¸´ ë©”ì‹œì§€ì˜ ë°”ì´íŠ¸ ê¸¸ì´ë¥¼ ì €ì¥í•  ë³€ìˆ˜ ì´ˆê¸°í™” (UTF-8 ê¸°ì¤€)
    max_msg_byte_length = 0 

    # DEFAULT_STATUS_TEMPLATEì— ìˆëŠ” ë©”ì‹œì§€ë“¤ (statusì— í•´ë‹¹í•˜ëŠ” í‚¤ë§Œ)ì˜ ìµœëŒ€ ë°”ì´íŠ¸ ê¸¸ì´ë¥¼ ê³„ì‚°
    for key in status.keys(): # Iterate over keys present in the status
        if key in DEFAULT_STATUS_TEMPLATE: # Check if the key has a defined message in the template
            msg_string = DEFAULT_STATUS_TEMPLATE[key]["msg"]
            
            # ë©”ì‹œì§€ ë¬¸ìì—´ì„ UTF-8ë¡œ ì¸ì½”ë”©í•œ í›„ ë°”ì´íŠ¸ ê¸¸ì´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
            current_byte_length = visual_length(msg_string, 2) 
            
            # í˜„ì¬ ë©”ì‹œì§€ì˜ ë°”ì´íŠ¸ ê¸¸ì´ê°€ ìµœëŒ€ ë°”ì´íŠ¸ ê¸¸ì´ë³´ë‹¤ í¬ë©´ ì—…ë°ì´íŠ¸
            if current_byte_length > max_msg_byte_length:
                max_msg_byte_length = current_byte_length

    # max_msg_byte_length ë³€ìˆ˜ì— ê°€ì¥ ê¸´ ë©”ì‹œì§€ì˜ UTF-8 ë°”ì´íŠ¸ ê¸¸ì´ê°€ ì €ì¥ë©ë‹ˆë‹¤.
    # print(f"ê°€ì¥ ê¸´ ë©”ì‹œì§€ì˜ UTF-8 ë°”ì´íŠ¸ ê¸¸ì´: {max_msg_byte_length}") # í™•ì¸ì„ ìœ„í•œ ì˜ˆì‹œ ì¶œë ¥

    fill_char = '.' # ì›í•˜ëŠ” ì±„ì›€ ë¬¸ìë¥¼ ì—¬ê¸°ì— ì§€ì •í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ '.' ë˜ëŠ” '-' ë“±
    # --- í†µê³„ ê²°ê³¼ ì¶œë ¥ ---
    logger.warning("--- ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬ í†µê³„ ---")
    for key, data in status.items():
        # DEFAULT_STATUS_TEMPLATEì— í•´ë‹¹ í‚¤ê°€ ìˆì„ ê²½ìš°ì—ë§Œ ë©”ì‹œì§€ë¥¼ ê°€ì ¸ì˜¤ê³ , ì—†ìœ¼ë©´ í‚¤ ì´ë¦„ì„ ì‚¬ìš©
        msg = DEFAULT_STATUS_TEMPLATE.get(key, {}).get("msg", key)
        value = data["value"]
        logger.warning(f'{msg:{fill_char}<{max_msg_byte_length}}: {value:{digit_width}}')
    logger.warning("------------------------")
    # --- í†µê³„ ê²°ê³¼ ì¶œë ¥ ë ---

if __name__ == "__main__":
    # 0. ì• í”Œë¦¬ì¼€ì´ì…˜ ì•„ê·€ë¨¼íŠ¸ ìˆìœ¼ë©´ ê°–ì˜¤ê¸°
    logger.info(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘")
    parsed_args = get_argument()

    # 1. logger ì¼í• ì¤€ë¹„ ì‹œí‚¤ê¸°ê¸°
    script_name = Path(__file__).stem # Define script_name early for logging
    try:
        # 1. ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê±° ì„¤ì •
        date_str = datetime.now().strftime("%y%m%d")
        log_file_name = f"{script_name}_{date_str}.log"
        full_log_path = Path(parsed_args.log_dir) / log_file_name
        logger.setup(
            logger_path=str(full_log_path),
            min_level=parsed_args.log_level,
            include_function_name=True,
            pretty_print=True
        )
        logger.info(f"ì• í”Œë¦¬ì¼€ì´ì…˜({script_name}) ì‹œì‘")
        logger.info(f"ëª…ë ¹ì¤„ ì¸ìë¡œ ê²°ì •ëœ ê²½ë¡œ: {vars(parsed_args)}")
    except Exception as e:
        print(f"ì¹˜ëª…ì  ì˜¤ë¥˜: ë¡œê±° ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {e}", file=sys.stderr)
        sys.exit(1)

    # 2. configger ì¼í•  ì¤€ë¹„ ì‹œí‚¤ê¸°ê¸°
    # configgerëŠ” ì´ì œ ìœ„ì—ì„œ ì„¤ì •ëœ ê³µìœ  loggerë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    # root_dirê³¼ config_pathëŠ” ì‹¤ì œ í”„ë¡œì íŠ¸ì— ë§ê²Œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.
    # ì„¤ì • íŒŒì¼ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    logger.info(f"Configger ì´ˆê¸°í™” ì‹œë„: root_dir='{parsed_args.root_dir}', config_path='{parsed_args.config_path}'")

    try:
        cfg_object = configger(root_dir=parsed_args.root_dir, config_path=parsed_args.config_path)
        logger.info(f"Configger ì´ˆê¸°í™” ë")
    except Exception as e:
        logger.error(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # 3. ë³¸ í”„ë¡œê·¸ë¨ ì‹œì‘ì‘
    logger.info(f" ì´ì œ ì¼í•˜ì ")
    try:
        run_main(cfg_object)
    except KeyError as e:
        logger.critical(f"ì„¤ì • íŒŒì¼ì—ì„œ í•„ìˆ˜ ê²½ë¡œ í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        sys.exit(1)
    except Exception as e:
        logger.critical(f"ì„¤ì • íŒŒì¼ì—ì„œ ê²½ë¡œ ì •ë³´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)
    finally:
        # ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ ë¡œê±° ì •ë¦¬ (íŠ¹íˆ ë¹„ë™ê¸° ì‚¬ìš© ì‹œ ì¤‘ìš”)
        logger.info(f"{script_name} ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ")
        logger.shutdown()
        exit(0)

    print("ëª¨ë“  JSON íŒŒì¼ ê²½ë¡œ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


